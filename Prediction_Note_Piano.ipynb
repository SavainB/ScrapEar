{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85778429",
   "metadata": {},
   "source": [
    "# Prédiction des Notes au Piano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339b3e77",
   "metadata": {},
   "source": [
    "\n",
    "Ce projet utilise l'apprentissage profond pour prédire des notes de piano à partir de fichiers audio. Les étapes incluent :\n",
    "\n",
    "1. Préparation des données\n",
    "2. Entraînement d'un modèle CNN\n",
    "3. Évaluation des performances avec des graphiques\n",
    "4. Prédictions sur de nouveaux fichiers audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf7b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importation des bibliothèques nécessaires\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d34a79a",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca674cb7",
   "metadata": {},
   "source": [
    "### Génération des Spectrogrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851e20d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Générer des spectrogrammes à partir de fichiers audio\n",
    "audio_folder = 'song'  # Chemin vers les fichiers audio\n",
    "output_folder = 'dataset'\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for file_name in os.listdir(audio_folder):\n",
    "    if file_name.endswith(('.wav', '.mp3')):\n",
    "        audio_path = os.path.join(audio_folder, file_name)\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "        S = np.abs(librosa.stft(y))\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max), sr=sr, y_axis='log', x_axis='time')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.title(file_name)\n",
    "        plt.savefig(f\"{output_folder}/{os.path.splitext(file_name)[0]}_spectrogram.png\")\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92d656e",
   "metadata": {},
   "source": [
    "![Spectograme](dataset/C3/c3-95007_spectrogramme.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa2509b",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "```plaintext\n",
    "├── dataset/\n",
    "│   ├── C/\n",
    "│   │   ├── spectrogram1.png\n",
    "│   │   ├── spectrogram2.png\n",
    "│   ├── D/\n",
    "│   ├── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f300d8d",
   "metadata": {},
   "source": [
    "## Chargement et Prétraitement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 2 : Chargement des données\n",
    "# Utilisation de ImageDataGenerator pour charger les spectrogrammes\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)  # Normalisation des images\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/',  # Répertoire contenant les sous-dossiers de notes\n",
    "    target_size=(256, 256),  # Taille des images\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'  # Utilisation de la classification catégorielle\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3c6b58",
   "metadata": {},
   "source": [
    "```plaintext\n",
    "\n",
    "├── Chargement des données/\n",
    "    ├── ImageDataGenerator/\n",
    "        ├── Applique une normalisation des images avec `rescale=1./255`.\n",
    "        ├── Convertit les pixels des images de 0-255 à une plage de 0-1.\n",
    "        ├── Objectif : Faciliter le traitement des données par le modèle et stabiliser l'entraînement.\n",
    "    ├── flow_from_directory/\n",
    "        ├── Charge automatiquement les images depuis le dossier `dataset/`.\n",
    "        ├── Organise les données en fonction des sous-dossiers correspondant aux classes (par exemple, A, B, C...).\n",
    "        ├── Redimensionne les images à une taille fixe de `(256, 256)` pour qu'elles soient compatibles avec l'entrée du modèle.\n",
    "        ├── Divise les données en **lots de 32 images** grâce au paramètre `batch_size=32`, ce qui optimise la mémoire.\n",
    "        ├── Définit la tâche comme une **classification multi-classes** avec `class_mode='categorical'`.\n",
    "            ├── Convertit les étiquettes des classes en vecteurs \"one-hot\" (exemple : A = [1, 0, 0, 0], B = [0, 1, 0, 0], etc.).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0bd740",
   "metadata": {},
   "source": [
    "## Création du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d703118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Création et compilation du modèle\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3165327",
   "metadata": {},
   "source": [
    "### Les couches (6 couches principales)\n",
    "```plaintext\n",
    "├── CNN/\n",
    "│   ├── Couches de traitement des motifs/\n",
    "│      ├── 2 couches Conv2D (convolutionnelles)\n",
    "│      ├── 2 couches MaxPooling2D (réduction de taille)\n",
    "│   ├── Couches de classification/\n",
    "│      ├── 1 couche Flatten (aplatissement des données)\n",
    "│      ├── 2 couches Dense (neurones entièrement connectés)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3959f67",
   "metadata": {},
   "source": [
    "### Plus en detail\n",
    "```plaintext\n",
    "├── CNN/\n",
    "    ├── Première couche Conv2D/\n",
    "        ├── Applique 32 filtres de taille (3x3) sur le spectrogramme.\n",
    "        ├── Détecte des motifs locaux simples.\n",
    "        ├── Rend le spectrogramme plus riche en motifs distinctifs.\n",
    "    ├── Première couche MaxPooling2D/\n",
    "        ├── Réduit la taille du spectrogramme en ne conservant que les maxima locaux (2x2).\n",
    "        ├── Diminue les détails inutiles tout en gardant les informations essentielles.\n",
    "        ├── Effet : Compresse les données tout en préservant les zones clés.\n",
    "    ├── Deuxième couche Conv2D/\n",
    "        ├── Applique 64 filtres de taille (3x3) pour capturer des motifs plus complexes.\n",
    "        ├── Identifie des relations entre les motifs simples trouvés par la première couche.\n",
    "        ├── Exemple : Repérer des formes ou textures sur le spectrogramme.\n",
    "    ├── Deuxième couche MaxPooling2D/\n",
    "        ├── Réduit encore la taille du spectrogramme (2x2).\n",
    "        ├── Diminue la complexité spatiale tout en gardant l'essentiel.\n",
    "        ├── Effet : Concentre les informations importantes sur des régions spécifiques.\n",
    "    ├── Flatten/\n",
    "        ├── Transforme le spectrogramme compressé en une grande liste linéaire.\n",
    "        ├── Effet : Prépare les données pour entrer dans les couches denses.\n",
    "    ├── Couches Dense/\n",
    "        ├── Dense (128 neurones) :\n",
    "            ├── Combine les motifs extraits en apprenant des relations complexes.\n",
    "            ├── Prépare des représentations plus abstraites pour la classification.\n",
    "        ├── Dense (sortie) :\n",
    "            ├── Applique la fonction softmax pour convertir les sorties en probabilités.\n",
    "            ├── Donne une probabilité pour chaque classe (note musicale prédite).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ee40e0",
   "metadata": {},
   "source": [
    "## Entraînement du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4c7d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Entraîner le modèle\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
    "\n",
    "# Sauvegarder le modèle\n",
    "model.save('mon_modele.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a3c9e2",
   "metadata": {},
   "source": [
    "## Visualisation des Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff57b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Courbes de perte et de précision\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Perte Entraînement')\n",
    "plt.plot(history.history['val_loss'], label='Perte Validation')\n",
    "plt.title('Courbe de Perte')\n",
    "plt.xlabel('Époque')\n",
    "plt.ylabel('Perte')\n",
    "plt.legend()\n",
    "plt.savefig('courbe_perte.png')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['accuracy'], label='Précision Entraînement')\n",
    "plt.plot(history.history['val_accuracy'], label='Précision Validation')\n",
    "plt.title('Courbe de Précision')\n",
    "plt.xlabel('Époque')\n",
    "plt.ylabel('Précision')\n",
    "plt.legend()\n",
    "plt.savefig('courbe_precision.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7542c1",
   "metadata": {},
   "source": [
    "## Matrice de Confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c8ca1a",
   "metadata": {},
   "source": [
    "![Spectograme](confusion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0288c73",
   "metadata": {},
   "source": [
    "## Courbe de Perte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b359d9",
   "metadata": {},
   "source": [
    "![Spectograme](perte.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e34f31",
   "metadata": {},
   "source": [
    "## Courbe de precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d7c078",
   "metadata": {},
   "source": [
    "![Spectograme](precision.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514bb066",
   "metadata": {},
   "source": [
    "## Prédiction sur un Nouvel audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ed313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Charger un modèle pré-entrainé et prédire une note\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = load_model('mon_modele.h5')\n",
    "\n",
    "audio_path = 'cnote.mp3'\n",
    "y, sr = librosa.load(audio_path, sr=None)\n",
    "S = np.abs(librosa.stft(y))\n",
    "plt.figure(figsize=(10, 6))\n",
    "librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max), sr=sr, y_axis='log', x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Spectrogramme')\n",
    "plt.savefig(\"spectrogramme_test.png\")\n",
    "plt.close()\n",
    "\n",
    "img_path = 'spectrogramme_test.png'\n",
    "img = image.load_img(img_path, target_size=(256, 256))\n",
    "img_array = image.img_to_array(img) / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "class_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "predicted_note = class_names[predicted_class[0]]\n",
    "\n",
    "print(f\"La note prédite est : {predicted_note}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e2fe13",
   "metadata": {},
   "source": [
    "## Résultat \n",
    "La note prédite est : G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b9fd35",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9f2a31",
   "metadata": {},
   "source": [
    "\n",
    "### Résultats\n",
    "- Le modèle est entraîné avec une précision de validation acceptable.\n",
    "- Les spectrogrammes permettent une bonne classification des notes.\n",
    "\n",
    "### Améliorations futures\n",
    "- Ne pas se limiter au piano\n",
    "- Prediction de plus de note \n",
    "- Conversion audio complet en midi \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
